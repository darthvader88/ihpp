
\documentclass[a4paper,11pt]{report}

\author{Vladislav K. Valtchev} 
\title{IHPP: An Intraprocedural Hot Path Profiler}


\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{hyperref}
\usepackage{xcolor,graphicx}
\usepackage{mdwlist}
\usepackage{fix-cm}

\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

%in order to make the analytical index
%\usepackage{makeidx}
%\makeindex

\pagestyle{headings}

\begin{document}

\thispagestyle{empty}

\begin{figure}
\centering
\includegraphics[scale=0.6]{logo}
\end{figure}


\begin{center}


{\Large\textsc{Universit\`a degli studi di Roma}\\} 
{\huge\textsc{La Sapienza}\\[10pt]}
{\huge\textsc{Facolt\`a di Ingegneria}\\[40pt]} 

{\large Tesi di laurea in: \\}
{\LARGE\textsc{Ingegneria Informatica}\\[50pt]}

{\large Docente relatore: \\}
{\large Prof. Camil Demetrescu\\[20pt]}

{\large Candidato: \\}
{\large \textbf{Vladislav K. Valtchev}\\[40pt]}

{\large Anno accademico: 2011/2012\\}


\end{center}

%in order to print the analytical index
%\printindex

\pagebreak

\thispagestyle{empty}

\begin{center}

\vspace*{4.5cm}

\fontsize{70}{90}\selectfont \textbf{IHPP}\\
\fontsize{20}{35}\selectfont
\textit{An Intraprocedural Hot Path Profiler}\\

\vspace{11cm}

\fontsize{14}{20}\selectfont
\textbf{Vladislav K. Valtchev}

\end{center}
\pagebreak

\begin{abstract}
dwehkhjrkweh rlkewrhwe lkrhwek rhwel krhjweklrh welkrh wekrhwe krhwr
werwerwekr h jwekj rhwk jrhwk rhwl kjrh k kqhe qe wrkjehr r hk rhj
wlhrwelkjrfh sd hf kjh sdfkh jq ql lkqjhekqj q eqhkjeqkj kjahq 
erhjwe skafhd lkaerh welrk liwer  iwerh wit wielr qierhu lqr 
dwehkhjrkweh rlkewrhwe lkrhwek rhwel krhjweklrh welkrh wekrhwe krhwr
werwerwekr h jwekj rhwk jrhwk rhwl kjrh k kqhe qe wrkjehr r hk rhj
wlhrwelkjrfh sd hf kjh sdfkh jq ql lkqjhekqj q eqhkjeqkj kjahq 
erhjwe skafhd lkaerh welrk liwer  iwerh wit wielr qierhu lqr 
dwehkhjrkweh rlkewrhwe lkrhwek rhwel krhjweklrh welkrh wekrhwe krhwr
werwerwekr h jwekj rhwk jrhwk rhwl kjrh k kqhe qe wrkjehr r hk rhj
wlhrwelkjrfh sd hf kjh sdfkh jq ql lkqjhekqj q eqhkjeqkj kjahq 
erhjwe skafhd lkaerh welrk liwer  iwerh wit wielr qierhu lqr 
dwehkhjrkweh rlkewrhwe lkrhwek rhwel krhjweklrh welkrh wekrhwe krhwr
werwerwekr h jwekj rhwk jrhwk rhwl kjrh k kqhe qe wrkjehr r hk rhj

\end{abstract}


\tableofcontents

\chapter{Introduction}


\section{The context (state of art)}
\section{Motivations}
\section{Contributions}
\section{Thesis structure}

\chapter{Program analysis}

Program analysis is the process of analyzing the behavior of computer programs\footnote{Program analysis: \url{http://en.wikipedia.org/wiki/Program_analysis}}. Main applications of program analysis are \emph{program correctness checking} and \emph{program optimization}.
There are two main approaches in program analysis: static and dynamic analysis.
The main difference between them is that in \emph{static} analysis nothing is executed: the analysis
is conducted only by observing the program source code or the compiled program instructions. Instead, the \emph{dynamic} program analysis is based on executing the program and observing what is it doing, even in real time if possible.

\section{Static analysis}

Static analysis can be done either by hand or by using another program. Information obtained by static analysis can be used in many ways, from highlighting possible coding errors to application of formal methods that mathematically prove the correctness of algorithms used or, in the general case, some properties. It's necessary to say, even if this isn't the right context, that, as 
theoretical computer science proved, there is no way to prove the absolute correctness of every program because of the halting problem\footnote{The halting problem: \url{http://en.wikipedia.org/wiki/Halting_problem}}.
By the way, there are a lot of methods that give us estimated solutions with a good level of reliability. We can mention four ways of doing static program
analysis\footnote{\url{http://en.wikipedia.org/wiki/Static_program_analysis}}:


\begin{description}
\item[Model checking] considers systems that have finite state or may be reduced to finite state by abstraction
\item[Data-flow analysis] is a lattice-based technique for gathering information about the possible set of values
\item[Abstract interpretation] models the effect that every statement has on the state of an abstract machine (i.e., it 'executes' the software based on the mathematical properties of each statement and declaration)
\item[Use of assertions] in program code as first suggested by Hoare logic\footnote{Hoare logic: \url{http://en.wikipedia.org/wiki/Hoare_logic}}
\end{description}

A more in deep explanation of these approaches goes too far away from the purpose of this paper.

\section{Dynamic analysis}

Dynamic program analysis is substantially done by executing the \emph{target program} in a sort of ``controlled environment''.
This description is so vague because there a lot of very different ways of doing this type of analysis as there are different objectives that who does the analysis wants to achieve. For example, it can be done in order to trace memory allocations (and discover memory leaks), to discover race conditions, memory corruption, security vulnerabilities and in general to do a \emph{performance analysis}, also known as \textbf{profiling}. We refer as \emph{profiling} when the final goal of the work is to improve the program  \emph{performance} and not, for example, to improve program \emph{correctness}. So, a memory analysis is always a dynamic analysis but isn't always a form of \emph{profiling}.

\subsection{The profiling}
The profiling is probably the most common form of dynamic program analysis and it's goal is, as just said, to analyze the performance of a program: the \emph{performance} can be the amount of memory used, the frequency of certain instructions, the frequency and/or the time consumption of some \emph{procedures} / \emph{basic blocks} inside certain procedures. Let's focus our attention on the last kind of profilers, we can classify them in two ways: according to the type of output and according to the method of data acquisition. Using the first classification rule, we get:

\begin{description}
\item[Flat profilers] \hfill \\
Profilers belonging to this kind count the number of function calls and/or average cpu time used by each function without keeping trace of the calling context of the function.
\item[Call-graph profilers] \hfill \\
These profilers do the same things that flat profilers do but they keep trace of the \emph{calling context} of a function or in the case of IHPP, also the \emph{``calling'' context} of the basic blocks (this will be explained in details later).
\end{description}

\begin{flushleft}
Instead, using the second classification method, we get:
\end{flushleft}


\begin{description}
\item[Event-based profilers] \hfill \\
Some high-level languages and frameworks have they ad-hoc profilers based on events. For example, Java has JVMPI \textit{(Java Virtual Machine Profiling Interface)}, while in .NET it's possible to attach a profiling agent as COM server to a .NET program using the \emph{Profiling APIs}. These profilers are called \emph{event-based} because statements (of the relative intermediate language) like function calls (or returns), object creations (and many others \ldots) have \emph{traps} handled at low-level by the relative virtual machine which generates \emph{events} and propagates these ones to the high-level user event-handlers objects.
\item[Statistical profilers] \hfill \\
This kind of profilers work by \emph{sampling} at regular intervals the \emph{instruction pointer} of target program through \emph{software interrupts}. This approach, of course, doesn't produce numerically exact data, but allows the program to run at near full speed. Common profilers of that kind are AMD CodeAnalyst, Apple Shark, Intel VTune and Intel Parallel Amplifier.
\item[Instrumentation profilers] \hfill \\

This kind of profilers are used for \emph{native programs}\footnote{A native program is a program written in a compiled language like C, C++, Pascal: the result of the building is an executable containing architecture-specific instructions. Instead, non-native programs (aka managed programs) don't contain binary instructions: they contain intermediate-language (IL) instructions which only the relative virtual machine understand. In order the program to run, their VM run-time compile IL instructions into machine specific instructions. \textbf{Java} and \textbf{.NET} technologies use intermediate languages called relatively \textbf{Bytecode} and \textbf{MSIL}.} and need to add binary instructions to the target program in order to ``catch events'' like function calls. Instrumentation profilers can be classified by the way they ``add instructions'' to the target program:

\begin{description}
\item[Manuale]
Il programmatore modifica il proprio programma inserendo del codice aggiuntivo nei punti che vuole studiare. Per esempio, può inserire all'inizio e prima di ogni \verb|return| di una certa funzione istruzioni per leggere l'ora del sistema. Prima che ogni chiamata della funzione ritorni al chiamante, è possibile fare la differenza fra i tempi e aggiornare un contatore temporale. In questo modo infine, sarà possibile capire il tempo cpu medio usato da quella funzione.
\item[Automatizzato a livello di codice]
Molto simile al metodo manuale, solo che in questo caso un tool aggiunge automaticamente le istruzioni supplementari al codice sorgente.
\item[Compiler assisted]
In questo caso il codice sorgente non viene toccato, ma è il compilatore stesso ad aggiungere durante la compilazione le ulteriori istruzioni. Un esempio è quando si compila con il \verb|gcc| usando l'opzione \verb|-pg|. Usando poi, un tool come \verb|gprof| è possibile far partire il programma in modalità \textit{profiling} e raccogliere i dati.
\item[Binary translation]
Questa tecnica consiste nell'aggiungere le istruzioni di profiling all'eseguibile già compilato in precedenza.
\item[Runtime instrumentation]
In questo caso le istruzioni aggiuntive vengono aggiunte subito prima che le istruzioni di quella parte del programma vengano eseguite. Affinché avvenga questo, un software deve avere deve eseguire il programma da analizzare sotto il suo completo controllo. Questo tipo di tecnica viene usata da software come \textbf{Valgrind} e \textbf{Intel Pin}, lo strumento per il quale è stato sviluppato il plug-in oggetto della trattazione. Per questo motivo, questa tecnica verrà approfondita in seguito.
\item[Runtime injection]
Questa tecnica è basata sullo stesso principio della runtime instrumentation, solo che è più \textit{lightweight} come approccio: consiste principalmente nell'inserire istruzioni di salto incondizionato a funzioni \textit{helper}. Un tool che fa uso di questa tecnica è \textbf{DynInst}.
\end{description} 
\item[Profiling tramite un hypervisor/simulator] \hfill \\
Questo tipo di profiler analizza il programma eseguendolo senza modifiche in una sorta di \textit{virtual machine} magari con l'aiuto di tecnologie hardware apposite oppure letteralmente emulando le istruzioni macchina del programma. Questo tipo di approccio oggi non è molto usato. Due software storici che usarono questa tecnica furono IBM SIMMON e IBM OLIVER. 
\end{description}


\chapter{The Approach: An Intraprocedural Hot Path Profiler}


\section{Algorithms and data structures used}

\chapter{The implementation}


\chapter{Evaluation: Case studies}


\chapter{Conclusions}

\end{document}